{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "class Params(object):\n",
    "    \"\"\"A parameters class which attributes are in fact a dict       \n",
    "    \"\"\"\n",
    "    def __init__(self, params={}):\n",
    "        self.params = params\n",
    "        \n",
    "    def __getattribute__(self,name):\n",
    "        try:\n",
    "            ret = object.__getattribute__(self, name)\n",
    "            return ret\n",
    "        except AttributeError:\n",
    "            t, v, tb = sys.exc_info()\n",
    "            if name in self.params:\n",
    "                return self.params[name]\n",
    "            raise v.with_traceback(tb)\n",
    "            \n",
    "    def __setattr__(self, name, value):\n",
    "        if name == \"params\":\n",
    "            super().__setattr__(name, value)\n",
    "        else:\n",
    "            self.params[name] = value\n",
    "\n",
    "class RnnLm(nn.Module):\n",
    "    def __init__(self, params):\n",
    "        \"\"\"\n",
    "            params: a 'Params' object with at least:\n",
    "                - vocab_size\n",
    "                - embed_dim\n",
    "                - hidden_size\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.params = params\n",
    "        \n",
    "        self.embedding = nn.Embedding(num_embeddings=params.vocab_size, \n",
    "                                      embedding_dim=params.embed_dim)\n",
    "        \n",
    "        self.cell = nn.LSTM(input_size=params.embed_dim, \n",
    "                            hidden_size=params.hidden_size,\n",
    "                            batch_first=True)\n",
    "        \n",
    "        self.out_w = autograd.Variable(torch.randn(params.hidden_size, params.vocab_size))\n",
    "        self.out_b = autograd.Variable(torch.randn(params.vocab_size))\n",
    "    \n",
    "    def _embed_data(self, src):\n",
    "        \"\"\"Embeds a list of words \n",
    "        \"\"\"\n",
    "        src_var = autograd.Variable(src)\n",
    "        embedded = self.embedding(src_var)\n",
    "        return embedded\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        # inputs: nested list [batch_size x time_steps]\n",
    "        # emb_inputs: [bs x ts x emb_size]\n",
    "        emb_inputs = self._embed_data(inputs) \n",
    "        log(\"Input: %s ; Embedded: %s \"% (str(inputs.size()), str(emb_inputs.size())))\n",
    "        \n",
    "\n",
    "        # Running the RNN\n",
    "        # o: [bs x ts x h_size]\n",
    "        # h: [n_layer x ts x h_size]\n",
    "        # c: [n_layer x ts x h_size]\n",
    "        o, (h, c) = self.cell(emb_inputs)\n",
    "        o = o.contiguous()\n",
    "        self.o = o\n",
    "        log(\"Outputs: %s\" % str(o.size()))\n",
    "        log(\"h %s\" % str(h.size()))\n",
    "        log(\"c %s\" % str(c.size()))\n",
    "        \n",
    "        \n",
    "        # Output projection\n",
    "        # oo: [bs*ts x h_size]\n",
    "        # logits: [bs*ts x vocab_size]\n",
    "        oo = o.view(-1, params.hidden_size)\n",
    "        \n",
    "        log(\"type: oo: %s; out_w: %s\" % (str(type(oo)), str(type(self.out_w))))\n",
    "        log(\"data type: oo: %s; out_w: %s\" % (str(type(oo.data)), str(type(self.out_w.data))))\n",
    "        \n",
    "        log(\"oo: %s\" % str(oo.size()))\n",
    "        log(\"w: %s\" % str(self.out_w.size()))\n",
    "        logits = oo @ self.out_w\n",
    "        logits = logits + self.out_b.expand_as(logits)\n",
    "        log(\"Logits: %s\" % str(logits.size()))\n",
    "        \n",
    "        # Softmax\n",
    "        prediction = F.log_softmax(logits)\n",
    "        \n",
    "        return prediction\n",
    "        \n",
    "def log(*args, **kwargs):\n",
    "    print(*args, **kwargs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import reader\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, params):\n",
    "        \"\"\"\n",
    "            params:\n",
    "                - data_path\n",
    "                - batch_size\n",
    "                - num_steps\n",
    "                - cuda: bool\n",
    "        \"\"\"\n",
    "        self.params = params\n",
    "        \n",
    "        print(\"Loading data...\")\n",
    "        self.train_data, self.valid_data, self.test_data, self.w2i = reader.raw_data(params.data_path)\n",
    "        print(\"Loaded\\t%d training words\\n\\t%d validation words\\n\\t%d test words\" % (\n",
    "                    len(self.train_data), len(self.valid_data), len(self.test_data)))\n",
    "        print(\"Vocabulary: %d\" % len(self.w2i))\n",
    "        self.eos = self.w2i['<eos>']\n",
    "        \n",
    "        print(\"Creating model...\")\n",
    "        \n",
    "        self.model = RnnLm(params)\n",
    "        if self.params.cuda:\n",
    "            print(\"Using CUDA\")\n",
    "            self.model.cuda()\n",
    "        print(\"Done.\")\n",
    "        \n",
    "    def batch_iterator(self, data):\n",
    "        return reader.iterator(data, self.params.batch_size, self.params.num_steps)\n",
    "    \n",
    "    def run_epoch(self):\n",
    "        import time\n",
    "        stime = time.time()\n",
    "        s = 0\n",
    "        num_iter = (len(self.train_data)/self.params.num_steps) / self.params.batch_size\n",
    "        print(num_iter)\n",
    "        log_step = int(num_iter / 20)\n",
    "        print(log_step)\n",
    "        for step, (xx, yy) in enumerate(self.batch_iterator(self.train_data)):\n",
    "            self.model.zero_grad()\n",
    "            \n",
    "            self.x = x = torch.LongTensor(xx.tolist())#.cuda()\n",
    "            y = torch.LongTensor(yy.tolist())\n",
    "            print_size(y, \"y\")\n",
    "            flat_y = y.view(-1, 1)\n",
    "            print_size(flat_y, \"flat_y\")\n",
    "            y_onehot = torch.FloatTensor(params.batch_size*params.num_steps, params.vocab_size)\n",
    "            y_onehot.zero_()\n",
    "            y_onehot.scatter_(1, flat_y, 1)\n",
    "            print_size(y_onehot, \"y_onehot\")\n",
    "            \n",
    "            if self.params.cuda:\n",
    "                self.x = x = x.cuda()\n",
    "                y_onehot = y_onehot.cuda()\n",
    "            \n",
    "            y_true = autograd.Variable(y_onehot)\n",
    "            \n",
    "            # Good discussions here\n",
    "            # http://stackoverflow.com/questions/34240703/difference-between-tensorflow-tf-nn-softmax-and-tf-nn-softmax-cross-entropy-with\n",
    "            # \n",
    "            # total_loss_1 = tf.reduce_mean(\n",
    "            #                    -tf.reduce_sum(y_true * tf.log(y_hat_softmax), reduction_indices=[1]))\n",
    "            #\n",
    "            # is ~equivalent to\n",
    "            # tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(y_hat, y_true))\n",
    "            # (difference comes from numerical instability)\n",
    "            #\n",
    "            # here: y_hat = pred = self.model(x)\n",
    "            # thus  y_hat_softmax = F.softmax(y_hat)\n",
    "            \n",
    "            y_hat = self.model(x)\n",
    "            y_hat_softmax = F.softmax(y_hat)\n",
    "            print_size(y_hat, \"y_hat\")\n",
    "            print_size(y_hat_softmax, \"y_hat_softmax\")\n",
    "            \n",
    "            loss_per_instance = -(y_true * y_hat_softmax.log()).sum(dim=1)\n",
    "            loss = loss_per_instance.mean()\n",
    "            \n",
    "            print_size(loss_per_instance, \"loss_per_instance\")\n",
    "            print_size(loss, \"loss\")\n",
    "            #print(loss)\n",
    "            #print(step)\n",
    "            s += float(loss.data[0])\n",
    "            loss.backward()\n",
    "            optimizer = optim.SGD(self.model.parameters(), lr=0.75)\n",
    "            optimizer.step()\n",
    "            \n",
    "            if step % log_step == (log_step-1):\n",
    "                _etime = time.time() - stime\n",
    "                _err = float(s)/float(step+1)\n",
    "                _words = (self.params.batch_size*self.params.num_steps*step)\n",
    "                _wps = _words / _etime\n",
    "                print(\"[%d] Err: %f\\twps: %.3f\" % (step, _err, _wps))\n",
    "        return float(s)/float(step+1)\n",
    "\n",
    "            \n",
    "def print_size(tensor, name):\n",
    "    pass\n",
    "    # print(\"%s: %s\" % (name, str(tensor.size())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = Params({\n",
    "    \"data_path\": \"./ptb\",\n",
    "    \"cuda\": True,\n",
    "    \n",
    "    \"vocab_size\": 10000,\n",
    "    \"embed_dim\": 200,\n",
    "    \"hidden_size\": 200,\n",
    "    \"batch_size\": 64,\n",
    "    \"num_steps\": 20\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Loaded\t929589 training words\n",
      "\t73760 validation words\n",
      "\t82430 test words\n",
      "Vocabulary: 10000\n",
      "Creating model...\n",
      "Using CUDA\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "tr = Trainer(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "726.24140625\n",
      "36\n",
      "Input: torch.Size([64, 20]) ; Embedded: torch.Size([64, 20, 200]) \n",
      "Outputs: torch.Size([64, 20, 200])\n",
      "h torch.Size([1, 64, 200])\n",
      "c torch.Size([1, 64, 200])\n",
      "type: oo: <class 'torch.autograd.variable.Variable'>; out_w: <class 'torch.autograd.variable.Variable'>\n",
      "data type: oo: <class 'torch.cuda.FloatTensor'>; out_w: <class 'torch.FloatTensor'>\n",
      "oo: torch.Size([1280, 200])\n",
      "w: torch.Size([200, 10000])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "torch.addmm received an invalid combination of arguments - got (int, torch.cuda.FloatTensor, int, torch.cuda.FloatTensor, torch.FloatTensor, out=torch.cuda.FloatTensor), but expected one of:\n * (torch.cuda.FloatTensor source, torch.cuda.FloatTensor mat1, torch.cuda.FloatTensor mat2, *, torch.cuda.FloatTensor out)\n * (torch.cuda.FloatTensor source, torch.cuda.sparse.FloatTensor mat1, torch.cuda.FloatTensor mat2, *, torch.cuda.FloatTensor out)\n * (float beta, torch.cuda.FloatTensor source, torch.cuda.FloatTensor mat1, torch.cuda.FloatTensor mat2, *, torch.cuda.FloatTensor out)\n * (torch.cuda.FloatTensor source, float alpha, torch.cuda.FloatTensor mat1, torch.cuda.FloatTensor mat2, *, torch.cuda.FloatTensor out)\n * (float beta, torch.cuda.FloatTensor source, torch.cuda.sparse.FloatTensor mat1, torch.cuda.FloatTensor mat2, *, torch.cuda.FloatTensor out)\n * (torch.cuda.FloatTensor source, float alpha, torch.cuda.sparse.FloatTensor mat1, torch.cuda.FloatTensor mat2, *, torch.cuda.FloatTensor out)\n * (float beta, torch.cuda.FloatTensor source, float alpha, torch.cuda.FloatTensor mat1, torch.cuda.FloatTensor mat2, *, torch.cuda.FloatTensor out)\n      didn't match because some of the arguments have invalid types: (\u001b[32;1mint\u001b[0m, \u001b[32;1mtorch.cuda.FloatTensor\u001b[0m, \u001b[32;1mint\u001b[0m, \u001b[32;1mtorch.cuda.FloatTensor\u001b[0m, \u001b[31;1mtorch.FloatTensor\u001b[0m, \u001b[32;1mout=torch.cuda.FloatTensor\u001b[0m)\n * (float beta, torch.cuda.FloatTensor source, float alpha, torch.cuda.sparse.FloatTensor mat1, torch.cuda.FloatTensor mat2, *, torch.cuda.FloatTensor out)\n      didn't match because some of the arguments have invalid types: (\u001b[32;1mint\u001b[0m, \u001b[32;1mtorch.cuda.FloatTensor\u001b[0m, \u001b[32;1mint\u001b[0m, \u001b[31;1mtorch.cuda.FloatTensor\u001b[0m, \u001b[31;1mtorch.FloatTensor\u001b[0m, \u001b[32;1mout=torch.cuda.FloatTensor\u001b[0m)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-200-c7a9a149611f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epoch %d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Avg Err: %f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-197-210d92d8f48e>\u001b[0m in \u001b[0;36mrun_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# thus  y_hat_softmax = F.softmax(y_hat)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m             \u001b[0my_hat_softmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mprint_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"y_hat\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/moses/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-192-57a79cfeceb5>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"oo: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"w: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_w\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moo\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_w\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_b\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Logits: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/moses/anaconda3/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36m__matmul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mdim_self\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdim_other\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 772\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    773\u001b[0m         raise ValueError(\"both arguments to __matmul__ need to be 1D or 2D, \"\n\u001b[1;32m    774\u001b[0m                          \"but they are {}D and {}D\".format(dim_self, dim_other))\n",
      "\u001b[0;32m/home/moses/anaconda3/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mmm\u001b[0;34m(self, matrix)\u001b[0m\n\u001b[1;32m    522\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 524\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_static_blas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAddmm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/moses/anaconda3/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36m_static_blas\u001b[0;34m(cls, args, inplace)\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnum_args\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m             \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_blas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/moses/anaconda3/lib/python3.6/site-packages/torch/autograd/_functions/blas.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, add_matrix, matrix1, matrix2)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madd_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         return torch.addmm(self.alpha, add_matrix, self.beta,\n\u001b[0;32m---> 28\u001b[0;31m                            matrix1, matrix2, out=output)\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: torch.addmm received an invalid combination of arguments - got (int, torch.cuda.FloatTensor, int, torch.cuda.FloatTensor, torch.FloatTensor, out=torch.cuda.FloatTensor), but expected one of:\n * (torch.cuda.FloatTensor source, torch.cuda.FloatTensor mat1, torch.cuda.FloatTensor mat2, *, torch.cuda.FloatTensor out)\n * (torch.cuda.FloatTensor source, torch.cuda.sparse.FloatTensor mat1, torch.cuda.FloatTensor mat2, *, torch.cuda.FloatTensor out)\n * (float beta, torch.cuda.FloatTensor source, torch.cuda.FloatTensor mat1, torch.cuda.FloatTensor mat2, *, torch.cuda.FloatTensor out)\n * (torch.cuda.FloatTensor source, float alpha, torch.cuda.FloatTensor mat1, torch.cuda.FloatTensor mat2, *, torch.cuda.FloatTensor out)\n * (float beta, torch.cuda.FloatTensor source, torch.cuda.sparse.FloatTensor mat1, torch.cuda.FloatTensor mat2, *, torch.cuda.FloatTensor out)\n * (torch.cuda.FloatTensor source, float alpha, torch.cuda.sparse.FloatTensor mat1, torch.cuda.FloatTensor mat2, *, torch.cuda.FloatTensor out)\n * (float beta, torch.cuda.FloatTensor source, float alpha, torch.cuda.FloatTensor mat1, torch.cuda.FloatTensor mat2, *, torch.cuda.FloatTensor out)\n      didn't match because some of the arguments have invalid types: (\u001b[32;1mint\u001b[0m, \u001b[32;1mtorch.cuda.FloatTensor\u001b[0m, \u001b[32;1mint\u001b[0m, \u001b[32;1mtorch.cuda.FloatTensor\u001b[0m, \u001b[31;1mtorch.FloatTensor\u001b[0m, \u001b[32;1mout=torch.cuda.FloatTensor\u001b[0m)\n * (float beta, torch.cuda.FloatTensor source, float alpha, torch.cuda.sparse.FloatTensor mat1, torch.cuda.FloatTensor mat2, *, torch.cuda.FloatTensor out)\n      didn't match because some of the arguments have invalid types: (\u001b[32;1mint\u001b[0m, \u001b[32;1mtorch.cuda.FloatTensor\u001b[0m, \u001b[32;1mint\u001b[0m, \u001b[31;1mtorch.cuda.FloatTensor\u001b[0m, \u001b[31;1mtorch.FloatTensor\u001b[0m, \u001b[32;1mout=torch.cuda.FloatTensor\u001b[0m)\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 10):\n",
    "    print(\"Epoch %d\" % i)\n",
    "    print(\"Avg Err: %f\" % tr.run_epoch())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
